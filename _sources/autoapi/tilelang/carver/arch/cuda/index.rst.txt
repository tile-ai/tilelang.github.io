tilelang.carver.arch.cuda
=========================

.. py:module:: tilelang.carver.arch.cuda


Classes
-------

.. autoapisummary::

   tilelang.carver.arch.cuda.CUDA


Functions
---------

.. autoapisummary::

   tilelang.carver.arch.cuda.is_cuda_arch
   tilelang.carver.arch.cuda.is_volta_arch
   tilelang.carver.arch.cuda.is_ampere_arch
   tilelang.carver.arch.cuda.is_ada_arch
   tilelang.carver.arch.cuda.is_hopper_arch
   tilelang.carver.arch.cuda.has_mma_support
   tilelang.carver.arch.cuda.is_tensorcore_supported_precision


Module Contents
---------------

.. py:function:: is_cuda_arch(arch)

.. py:function:: is_volta_arch(arch)

.. py:function:: is_ampere_arch(arch)

.. py:function:: is_ada_arch(arch)

.. py:function:: is_hopper_arch(arch)

.. py:function:: has_mma_support(arch)

.. py:function:: is_tensorcore_supported_precision(in_dtype, accum_dtype, arch)

.. py:class:: CUDA(target)

   Bases: :py:obj:`tilelang.carver.arch.arch_base.TileDevice`


   .. py:attribute:: target


   .. py:attribute:: sm_version


   .. py:attribute:: name


   .. py:attribute:: device
      :type:  tvm.runtime.Device


   .. py:attribute:: platform
      :type:  str
      :value: 'CUDA'



   .. py:attribute:: smem_cap


   .. py:attribute:: compute_max_core


   .. py:attribute:: warp_size


   .. py:attribute:: compute_capability


   .. py:attribute:: reg_cap
      :type:  int
      :value: 65536



   .. py:attribute:: max_smem_usage
      :type:  int


   .. py:attribute:: sm_partition
      :type:  int
      :value: 4



   .. py:attribute:: l2_cache_size_bytes
      :type:  int


   .. py:attribute:: transaction_size
      :type:  list[int]
      :value: [32, 128]



   .. py:attribute:: bandwidth
      :type:  list[int]
      :value: [750, 12080]



   .. py:attribute:: available_tensor_instructions
      :type:  list[TensorInstruction]
      :value: None



   .. py:method:: get_avaliable_tensorintrin_shapes()


   .. py:method:: __repr__()


